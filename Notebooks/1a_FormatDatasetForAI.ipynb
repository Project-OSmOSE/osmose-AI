{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8569b078-9152-4992-ae9e-d51a50b81447",
   "metadata": {},
   "source": [
    "# Format datasets for the trainning on a specific task \n",
    "\n",
    "Nb : checker l'ordre des fichiers dans le csv\n",
    "\n",
    "\n",
    "## Import functions \n",
    "\n",
    "#### <span style=\"color:blue\">*JUST RUN CELL*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b92189-b7d0-49c0-9a5d-8076091bb043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_codes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_codes.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     codes_path \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(codes_path))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_codes.txt'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "with open('path_codes.txt') as f:\n",
    "    codes_path = f.readlines()[0]\n",
    "os.chdir(os.path.join(codes_path))\n",
    "\n",
    "from format_dataset_for_ai import FormatDatasets_main\n",
    "from launcher_datasetScale import list_datasets\n",
    "from check_files_in_ai_folders import check_available_ai_tasks_bm, check_available_annotation, check_available_file_resolution, check_available_labels_annotators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f82540c-1db4-4699-b564-21e76fb7d4f3",
   "metadata": {},
   "source": [
    "## Select Datasets, task, benchmark, ...\n",
    "\n",
    "\n",
    "#### <span style=\"color:green\">*List of available datasets*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade424fb-6d6e-4828-a3ff-af281a59a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      "  - APOCADO_IROISE_C2D1_07072022\n",
      "  - BlueFinLibrary_BallenyIslands2015\n",
      "  - BlueFinLibrary_ElephantIsland2013Aural\n",
      "  - BlueFinLibrary_ElephantIsland2014\n",
      "  - BlueFinLibrary_Greenwich64S2015\n",
      "  - BlueFinLibrary_MaudRise2014\n",
      "  - BlueFinLibrary_RossSea2014\n",
      "  - BlueFinLibrary_casey2014\n",
      "  - BlueFinLibrary_casey2017\n",
      "  - BlueFinLibrary_kerguelen2005\n",
      "  - BlueFinLibrary_kerguelen2014\n",
      "  - BlueFinLibrary_kerguelen2015\n",
      "  - Dataset2015_AUS\n",
      "  - Glider\n",
      "  - MPSU_ForestouHuella\n",
      "  - MPSU_ForestouHuella_copy\n",
      "  - reshape_sr_3.py\n"
     ]
    }
   ],
   "source": [
    "list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06fa71f-6ba7-4132-8d5e-db1c11d3e17c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">*Select your dataset(s)*</span>\n",
    "\n",
    "Nb : Select on or several datasets as a list. \n",
    "\n",
    "Ex : \n",
    "- ``dataset_ID_tab`` = ['dataset1', 'dataset2', 'dataset3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589b0b3c-e963-4eb7-bfc2-1e0bfa3aabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ID_tab = ['Glider', 'Dataset2015_AUS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52cc38-16cc-4981-a302-d2f2628633d4",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">*List of available data format and annotation file*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d6dbe0-9272-4ae3-8cc6-31c2ca451f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  Glider\n",
      "Available Resolution (LengthFile_samplerate) :\n",
      "    \n",
      "    50_500\n",
      "    original\n",
      "    50_250\n",
      "__________\n",
      "Dataset :  Glider\n",
      "Available Annotation files :\n",
      "  \n",
      "    APLOSE_Glider_SPAmsLF_ManualAnnotations_V2_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_ALL_19Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_4Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_5Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_6Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_7Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_8Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_9Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_10Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_11Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_12Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_13Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_14Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_15Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_EXPERT_results.csv\n",
      "    APLOSE_Glider_SPAmsLF_ManualAnnotations_V2_ShortBbAus_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_EXPERT_ShortBbAus_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_2_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_3_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_4_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_5_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_6_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_7_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_8_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_9_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_10_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_1Neo_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_2_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_3_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_4_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_5_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_6_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_7_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_8_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_9_results.csv\n",
      "    20210420_Astrolabe_xOSmOSE-Campagne_participative_GROUPED_2Neo_10_results.csv\n",
      "    APLOSE_Glider_SPAmsLF_ManualAnnotations_V2_ShortBbAus_TODELETE_results.csv\n",
      "    APLOSE_Glider_SPAmsLF_ManualAnnotations_V2_LongBbAus_TODELETE_results.csv\n",
      "__________\n",
      "Dataset :  Dataset2015_AUS\n",
      "Available Resolution (LengthFile_samplerate) :\n",
      "    \n",
      "    23301_240\n",
      "    50_250\n",
      "__________\n",
      "Dataset :  Dataset2015_AUS\n",
      "Available Annotation files :\n",
      "  \n",
      "    Dataset2015_AUS_results.csv\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "for dataset_ID in dataset_ID_tab:\n",
    "    check_available_file_resolution(dataset_ID)\n",
    "    print('__________')\n",
    "    check_available_annotation(dataset_ID)\n",
    "    print('__________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf1bbd-81c2-4523-b027-23312eed3e87",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">*Select format(s) and annotation tab(s)*</span>\n",
    "\n",
    "Nb : As list, same dimension as the dataset_ID_tab. \n",
    "\n",
    "Ex :\n",
    "- ``LenghtFile_tab`` = [50,50,60] (in seconds)\n",
    "- ``sample_rate_tab`` = [48000, 44100, 48000] (in hertz)\n",
    "- ``file_annotation_tab`` = ['annotation_aplose1_results.csv', 'annotation_aplose3_results.csv', 'annotation_aplose3_results.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afad78a2-a27f-45b7-9ea8-45f77d3f2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "LenghtFile_tab = [50, 50]\n",
    "sample_rate_tab = [250, 250]\n",
    "file_annotation_tab = ['APLOSE_Glider_SPAmsLF_ManualAnnotations_V2_ShortBbAus_results.csv', 'Dataset2015_AUS_results.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67d3b5-5c2e-43b5-9227-34dcaea7f4ac",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">*List of existing tasks and benchmarks*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3fdab0-5f65-4edd-826a-b07b4d7c6a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "TaskTEST1/\n",
      "    BMTEST1_1/\n",
      "             Dataset used :  ['MPSU_ForestouHuella' 'MPSU_ForestouHuella_copy']\n",
      "Task_Glider_PBW_AnnotatorAnalysis/\n",
      "    BM_merged15/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_EXP/\n",
      "             Dataset used :  ['Glider']\n",
      "    Comp_BM_curves/\n",
      "    BM_merged6/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_2/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_3/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_4/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_5/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_6/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_7/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_8/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged8/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged10/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged12/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged14/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_9/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_merged2_10/\n",
      "             Dataset used :  ['Glider']\n",
      "    WeakLabelling_AllAnnotation/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Nassau/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Shanghai/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Civitavecchia/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Galveston/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Venice/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Fukuoka/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Naples/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Bridgetown/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Valletta/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Rostock/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Dubrovnik/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Mahahual/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Ensenada/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Tunis/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Funchal/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Tallinn/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Malaga/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Helsinki/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_AN_Valencia/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_FULL_EVAL/\n",
      "             Dataset used :  ['Glider']\n",
      "    BM_FULL_EVAL_long/\n",
      "             Dataset used :  ['Glider']\n",
      "Task_Test_Apocado_whistles/\n",
      "    BM_1/\n",
      "             Dataset used :  ['APOCADO_IROISE_C2D1_07072022']\n",
      "Task_Det_PBW/\n",
      "    TEST1/\n",
      "             Dataset used :  ['Dataset2015_AUS']\n",
      "    TRAIN_Glider/\n",
      "             Dataset used :  ['Glider']\n",
      "    TRAIN_Glider_long/\n",
      "             Dataset used :  ['Glider']\n",
      "    Train_multilabels_grouped15/\n",
      "             Dataset used :  ['Glider']\n"
     ]
    }
   ],
   "source": [
    "check_available_ai_tasks_bm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e718d-8bff-4f43-bbe4-d6437155686c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">*Select your task and benchmark*</span>\n",
    "\n",
    "- `` Task_ID `` : The First Level is for the Task. One task is composed by several benchmark.\n",
    "- ``BM_Name`` : The Second Level is for the BenchMark - . A BenchMark is composed by different model that will be compared. (Different architecture, different dataset subdivision, differents representation, ...)\n",
    "\n",
    "Nb : If you chose a new one, folders will be created automatically. \n",
    "\n",
    "Nb2 : Just enter strings\n",
    "\n",
    "Ex : \n",
    "- ``Task_ID`` = 'TaskTEST1'\n",
    "- ``BM_Name`` = 'BMTEST1_1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b9eebd-0727-461f-8638-0557ca63e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task_ID = 'Task_Det_PBW'\n",
    "BM_Name = 'Train_mergeboths'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32720e-df57-4769-a5a8-8728698bcce2",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">*List of existing annototated labels and annotators for each datasets*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7deee551-63fe-44bd-bbfd-1c95151a7436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :  Glider\n",
      "Labels Annotated :  ['Bb.Aus', 'Bb.Mad', 'Bm.P', 'Bm.D', 'Bm.Ant']\n",
      "Annotators :  ['Julie']\n",
      "__________\n",
      "Dataset :  Dataset2015_AUS\n",
      "Labels Annotated :  ['Bw.Ant']\n",
      "Annotators :  ['expert']\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_ID_tab)):\n",
    "    print('Dataset : ', dataset_ID_tab[i])\n",
    "    check_available_labels_annotators(dataset_ID_tab[i], file_annotation_tab[i])\n",
    "    print('__________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec007e-9d8e-4d04-9b03-d70b54003fad",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">*Select the annotators and the labels to be detected*</span>\n",
    "\n",
    "- ``AnnotatorsList_tab`` : Annotators selected by dataset. As list of list, same dimension as the dataset_ID_tab. \n",
    "    - Ex : ``AnnotatorsList_tab`` = [['annotatorA', 'annotatorB'], ['annotatorC'], [['annotatorD', 'annotatorE']] \n",
    "    - Means that annotator A and B are selected for the dataset1, annotator C for the dataset2, and annotators D and E for the dataset3.\n",
    "\n",
    "</br>\n",
    "\n",
    "- ``orig_LabelsList_tab`` : label to be kept for the detection, for each dataset. As list of list, same dimension as the dataset_ID_tab.\n",
    "    - Ex : ``orig_LabelsList_tab`` = [['whistles'], ['click', 'whistle'], [['dolphins_clicks', 'globi_clicks']] \n",
    "    - Means that the label 'whistles' is selected for the dataset1, labels 'click' and 'whistles' for the dataset2, and labels 'dolphins_clicks' and 'globi_clicks' for the dataset3.\n",
    "\n",
    "</br>\n",
    "\n",
    "- ``FinalLabel_Dic`` : labels used for the detectors. Allows you to merge some label from different dataset. As a dictionnary where keys are final labels and each one leads to a list with labels from \"orig_LabelsList_tan\".\n",
    "    - Ex : ``FinalLabel_Dic`` = {'Whistles':['whistles', 'whistle'], 'Clicks':['click', 'dolphins_clicks', 'globi_clicks']}\n",
    "    - Means that labels 'whistles' and 'whistle' will be merged as one label called 'Whistles', and the labels 'click', 'dolphins_clicks' and  'globi_clicks' will be merged as one label called 'Clicks'. \n",
    "\n",
    "</br>\n",
    "\n",
    "- ``Crop_duration`` : Time (in second) cropped at the start and end of the annotation (if you think the annotation does not exactly fit the sound of interest). \n",
    "    - Ex : ``Crop_duration`` = 1\n",
    "    - Ex2 : ``Crop_duration`` = 0 (if you do not want to crop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615cea90-10fe-40ae-bc2f-8810ae309d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnnotatorsList_tab = [['Julie', 'mtorte'], ['expert']]\n",
    "\n",
    "orig_LabelsList_tab = [[\"Bb.Aus\"], ['Bw.Ant']]\n",
    "\n",
    "FinalLabel_Dic = {'B':[\"Bb.Aus\", \"Bw.Ant\"]}\n",
    "\n",
    "Crop_duration = 3 #seconds #Pourcentage de la boite\n",
    "is_box = None #0, 1 ou None\n",
    "\n",
    "LabelType = 'classic' #\"soft_labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eedf12-f114-400a-b78a-129813228460",
   "metadata": {},
   "source": [
    "## Launch Formatting\n",
    "\n",
    "#### <span style=\"color:blue\">*JUST RUN CELL*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c5e48a-5fea-4771-a2f8-d65839d0f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset : Glider\n",
      "Task Status existing : we're removing all unannotated files ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54888/54888 [08:22<00:00, 109.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, 33504 files remains\n",
      "Matching annotation with timestamp for each label ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10145/10145 [00:02<00:00, 3947.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bb.Aus OK\n",
      "   \n",
      "Processing dataset : Dataset2015_AUS\n",
      "Done, 5137 files remains\n",
      "Matching annotation with timestamp for each label ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1122/1122 [00:00<00:00, 16029.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bw.Ant OK\n",
      "   \n",
      "Merging All Datasets ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33504/33504 [00:00<00:00, 142224.69it/s]\n",
      "100%|██████████| 5137/5137 [00:00<00:00, 146693.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files :  38641\n",
      "Bm.Aus  -> ratio of positive :      37.918 %\n",
      "DONE ! \n",
      "Next step : Define DEV [train+val] and EVAL sets for your network !\n"
     ]
    }
   ],
   "source": [
    "FormatDatasets_main(Task_ID, BM_Name, LenghtFile_tab, sample_rate_tab, dataset_ID_tab, file_annotation_tab, orig_LabelsList_tab, FinalLabel_Dic, AnnotatorsList_tab, Crop_duration, is_box, LabelType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee9270-ef41-480a-b86e-2e550577ee51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a17de3-41ec-495a-9081-8c8c3e3d04bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08825897-617c-40a2-9aa6-2fe8d0c1383f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c596b57-f5dc-4533-a627-b65740523ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38646a35-10e0-4f33-aa42-f2bb6000ed85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b54597-e897-4a49-9a59-7f327c2613f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a50ee-62e6-430e-8993-9a3528b3906b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a491a-9bab-4fa6-a930-3bde670ed4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0336b5-55cd-4c5a-8f02-1367fac6aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    " [[AN_list[i]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913df40-f152-42c3-98f7-61e13ff856aa",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">*Exemple if you want to format iteratively several datasets, tasks, annotation sets, ...*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb43485-a80c-4bec-bec6-6db86c90d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "AN_list = ['Nassau', 'Shanghai', 'Civitavecchia', 'Galveston', 'Venice', 'Fukuoka', 'Naples', 'Bridgetown', 'Valletta', 'Rostock', 'Dubrovnik', 'Mahahual', 'Ensenada', 'Tunis', 'Funchal', 'Tallinn','Malaga', 'Helsinki', 'Valencia']\n",
    "\n",
    "for i in range(len(AN_list)):\n",
    "    LenghtFile_tab = [50]\n",
    "    sample_rate_tab = [500]\n",
    "\n",
    "    Task_ID = 'Task_Glider_PBW_AnnotatorAnalysis'\n",
    "\n",
    "    BM_Name = 'BM_AN_'+AN_list[i]\n",
    "    \n",
    "    file_annotation_tab = ['20210420_Astrolabe_xOSmOSE-Campagne_participative_results.csv']\n",
    "    \n",
    "    \n",
    "    AnnotatorsList_tab = [[AN_list[i]]]\n",
    "    \n",
    "    orig_LabelsList_tab = [[\"Baleine Bleue d'Australie\"]]\n",
    "    \n",
    "    FinalLabel_Dic = {'Bm.Aus':[\"Baleine Bleue d'Australie\"]}\n",
    "    \n",
    "    Crop_duration = 2 #seconds\n",
    "    is_box = None\n",
    "    \n",
    "    LabelType = \"classic\"\n",
    "\n",
    "    FormatDatasets_main(Task_ID, BM_Name, LenghtFile_tab, sample_rate_tab, dataset_ID_tab, file_annotation_tab, orig_LabelsList_tab, FinalLabel_Dic, AnnotatorsList_tab, Crop_duration, is_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca27540-8fa5-4d96-9fc5-1793f49a5f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
